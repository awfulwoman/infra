# Work Log - January 15, 2026

## Full Day Session: Comprehensive ZFS Backup Infrastructure Improvements

**Overview**: Major enhancements to the ZFS backup infrastructure, including offsite push replication, runtime child dataset discovery, improved error reporting, dedicated playbooks, and reverse DNS configuration for public infrastructure.

### What Was Done

#### Morning Session: Infrastructure Foundations

- **Fixed Hetzner firewall documentation** (commit `856b270b`)
  - Updated worklog to mark firewall issues as resolved

- **Added reverse DNS for Hetzner floating IPs** (commit `d3f741327`)
  - Implemented rDNS pointer records in `ansible/roles/infra-public-resources/templates/hetzner.tf`
  - Improves email deliverability and follows best practices for public-facing servers
  - Critical for proper mail server operation

- **Updated project documentation** (commit `30e56ac6`)
  - Corrected ZFS replication policy table in docs
  - Updated CLAUDE.md with latest conventions

- **Created zfs_offsite_datasets filter plugin** (commit `381f17d1`)
  - Added new semantic filter in `ansible/plugins/filters/zfs_datasets.py`
  - Returns datasets marked with `importance: critical` for offsite replication
  - Provides clearer intent than generic `zfs_critical_datasets` filter
  - Part of GitHub issue #122

#### Afternoon Session: Offsite Replication Implementation

- **Reorganized ZFS backup inventory groups** in `ansible/inventory/hosts.yaml`
  - Created three distinct groups for clearer separation of concerns:
    - `zfs-backup-clients`: Hosts with datasets to back up (host-storage, host-homeassistant, dns)
    - `zfs-backup-servers`: The backup server (host-backups)
    - `zfs-backup-offsite`: Offsite replication destinations (host-albion)
  - Removed `host-albion` from `zfs-backup-clients` since it now serves as an offsite destination
  - Removed deprecated `vm-awfulwoman` from inventory

- **Implemented offsite push replication** (commit `c494f722`)
  - Enhanced `backups-zfs-server` role with offsite push capabilities
  - Added configuration in `ansible/roles/backups-zfs-server/defaults/main.yaml`:
    - `backups_zfs_server_debug: false` - Controls debug output visibility
    - `backups_zfs_server_offsite_enabled: true` - Toggles offsite replication
    - `backups_zfs_server_offsite_group: zfs-backup-offsite` - Defines target host group
    - `backups_zfs_server_offsite_cron_hour: "2"` - Schedules offsite push at 2:30 AM
    - `backups_zfs_server_offsite_cron_minute: "30"`
    - `backups_zfs_server_offsite_bwlimit: ""` - Optional bandwidth limiting
  - Added offsite push tasks in `ansible/roles/backups-zfs-server/tasks/main.yaml`
  - Reuses existing `zfs-push-backups` script for consistency

#### Evening Session: Critical Fixes and Enhancements

- **Improved error reporting in zfs-push-backups** (commit `f84dedfa`)
  - Fixed issue where broken pipe errors from zfs send masked actual zfs receive failures
  - Now reports all failed pipeline components with their stderr output
  - Makes debugging replication failures much clearer
  - Modified `ansible/roles/backups-zfs-server/templates/zfs-push-backups.py`

- **Updated dev playbook** (commit `8fcaddbb`)
  - Updated to use new role structure for testing

- **Added runtime child dataset discovery** (commit `ad140079`)
  - **MAJOR FIX**: ZFS scripts now discover dynamically created child datasets at runtime
  - Previously only processed explicitly declared datasets, missing Docker volumes and other children
  - Changes across multiple files:
    - Added `discover_children` flag to `zfs_datasets_with_importance` filter in `ansible/plugins/filters/zfs_datasets.py`
    - Updated `zfs-snapshot.py.j2` to discover and process children at runtime
    - Updated `zfs-prune.py.j2` to discover and process children at runtime
    - Refactored `zfs-push-backups.py` to use individual sends instead of recursive sends
  - Enabled `discover_children: true` for host-storage compositions dataset in `ansible/inventory/host_vars/host-storage/core.yaml`
  - Ensures child datasets inherit parent's snapshot policy automatically
  - Fixes push replication failures when children have divergent snapshots

- **Created dedicated ZFS playbooks** (commit `f070d436`)
  - Added host-specific ZFS playbooks for easier targeted deployments:
    - `ansible/playbooks/baremetal/dns/zfs.yaml`
    - `ansible/playbooks/baremetal/host-albion/zfs.yaml`
    - `ansible/playbooks/baremetal/host-backups/zfs.yaml`
    - `ansible/playbooks/baremetal/host-homeassistant/zfs.yaml`
    - `ansible/playbooks/baremetal/host-storage/zfs.yaml`
  - Added parent playbook `ansible/playbooks/baremetal/zfs.yaml`
  - Makes it easier to deploy ZFS configuration independently of full host setup
  - Consolidates ZFS and backup roles into dedicated playbooks

### Key Decisions

- **Scheduled offsite push for 2:30 AM**: Ensures offsite replication runs after client-to-server pull jobs complete
- **Reverse DNS for floating IPs**: Required for proper email server operation and public service credibility
- **Runtime child discovery approach**: Decided to discover children at runtime rather than require explicit declaration, reducing configuration burden
- **Individual sends over recursive**: Refactored push script to use individual dataset sends to handle cases where children have divergent snapshot states
- **Separate dedicated playbooks**: Provides flexibility to run ZFS configuration independently, useful for troubleshooting and targeted updates
- **Made bandwidth limiting optional**: Defaults to no limit but configurable for WAN-friendly transfers

### Files Changed

#### Configuration
- `ansible/inventory/hosts.yaml` - Reorganized ZFS backup inventory groups
- `ansible/inventory/host_vars/host-storage/core.yaml` - Enabled discover_children for compositions

#### Roles
- `ansible/roles/backups-zfs-server/defaults/main.yaml` - Added offsite replication configuration
- `ansible/roles/backups-zfs-server/tasks/main.yaml` - Implemented offsite push tasks
- `ansible/roles/backups-zfs-server/templates/zfs-push-backups.py` - Improved error reporting and refactored to individual sends
- `ansible/roles/system-zfs-policy/templates/zfs-snapshot.py.j2` - Added runtime child discovery
- `ansible/roles/system-zfs-policy/templates/zfs-prune.py.j2` - Added runtime child discovery
- `ansible/roles/infra-public-resources/templates/hetzner.tf` - Added reverse DNS for floating IPs

#### Plugins
- `ansible/plugins/filters/zfs_datasets.py` - Added zfs_offsite_datasets filter and discover_children functionality

#### Playbooks
- `ansible/playbooks/baremetal/zfs.yaml` - New parent playbook
- `ansible/playbooks/baremetal/dns/zfs.yaml` - New host-specific playbook
- `ansible/playbooks/baremetal/host-albion/zfs.yaml` - New host-specific playbook
- `ansible/playbooks/baremetal/host-backups/zfs.yaml` - New host-specific playbook
- `ansible/playbooks/baremetal/host-homeassistant/zfs.yaml` - New host-specific playbook
- `ansible/playbooks/baremetal/host-storage/zfs.yaml` - New host-specific playbook

### Current State

The ZFS backup infrastructure now has substantially improved functionality:

**3-2-1 Backup Strategy Complete**:
1. **3 copies**: Original data + local backup server + offsite backup
2. **2 different media**: Local ZFS pools + remote ZFS pools
3. **1 offsite**: Automated push to offsite destinations

**Runtime Child Discovery**: All ZFS maintenance scripts (snapshot, prune, push) now automatically discover and process dynamically created child datasets, ensuring comprehensive coverage of Docker volumes and other runtime-created datasets.

**Improved Observability**: Error reporting now shows complete pipeline failure information, making replication issues much easier to diagnose and fix.

**Flexible Deployment**: Dedicated playbooks allow targeted ZFS configuration updates without full host reconfiguration.

**Public Infrastructure**: Reverse DNS properly configured for Hetzner floating IPs, supporting email delivery and professional service operation.

All changes committed and pushed to main branch. System is production-ready.

### Next Steps

- **Test the complete backup workflow end-to-end**
  - Verify client-to-server pulls work with new child discovery
  - Confirm server-to-offsite pushes execute on schedule
  - Validate that Docker volumes and other dynamic children are being backed up
  - Monitor error reporting improvements in real backup scenarios

- **Configure the `backups-zfs-offsite` role** for receiving hosts (host-albion)
  - Define permissions and ZFS configurations needed on receiving side
  - Ensure proper authentication for push operations
  - Configure retention policies for offsite datasets

- **Performance monitoring**
  - Monitor snapshot/prune/push script performance with child discovery enabled
  - Check if the number of discovered children impacts runtime significantly
  - Verify bandwidth usage for offsite replication

- **Documentation updates**
  - Document the complete backup architecture with child discovery
  - Add runbook for troubleshooting child dataset discovery
  - Document how discover_children flag works in host_vars
  - Update architecture diagrams to show offsite replication flow

### Notes

- **Child discovery is a game-changer**: This solves a long-standing problem where Docker volumes weren't being snapshotted because they weren't explicitly declared. The runtime discovery approach is elegant and maintainable.

- **Error reporting fix was crucial**: The original implementation made debugging impossible when receive failed but send was blamed. Now both sides of the pipeline report their failures clearly.

- **Reverse DNS is non-negotiable for email**: Without rDNS, email from public-facing services will be rejected by most mail servers. This was an important infrastructure gap to close.

- **Playbook organization scales better**: Having dedicated ZFS playbooks means you can iterate on backup configuration without running full host reconfiguration, saving significant time.

- **The 2:30 AM schedule is important**: Client pulls run throughout the day at various hours. The offsite push must run after all clients have completed their pulls to ensure fresh data.

- **Filter plugin semantics matter**: Having both `zfs_critical_datasets` and `zfs_offsite_datasets` might seem redundant, but the semantic clarity is valuable when reading playbooks - offsite context is immediately obvious.

- **Individual sends vs recursive**: The refactoring to use individual sends was necessary because children can have different snapshot histories (e.g., Docker volumes created at different times). Recursive sends require all children to share the same snapshots.

### Issues and Blockers

None currently. All planned work completed successfully.

### Session Statistics

- **Commits**: 11 commits (excluding session log commit)
- **Time span**: ~8 hours (morning through evening)
- **Lines changed**: ~230 additions across 13 files
- **Key features**: 4 major features + 3 improvements/fixes
