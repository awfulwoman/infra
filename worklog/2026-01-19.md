# Work Log - 2026-01-19

## Session Overview

Completed migration from NetworkManager/nmcli to netplan for network configuration across all Ubuntu servers. Implemented unified role supporting both static and DHCP modes with automatic detection, tested on belinda and dns hosts, and removed legacy unused roles.

## What Was Done

### Network Configuration Migration (Issue #83)

- **Created `network-netplan` role** - Unified role for managing primary network interface configuration
  - Auto-detects DHCP vs static mode based on `host_ipv4` variable presence
  - Supports both static IP and DHCP configurations via single template
  - Uses networkd renderer (matches existing virtual-hetzner pattern)
  - Disables cloud-init network management to prevent conflicts
  - Removes cloud-init's netplan configuration file

- **Updated all Ubuntu host configurations** (7 hosts total)
  - Added `host_primary_interface` variable to all hosts
  - Added `host_ipv4_subnet: 24` to static IP hosts
  - Excluded pikvm (runs Arch Linux/PiKVM OS, not Ubuntu)
  - Static hosts: host-storage, belinda, host-homeassistant, host-backups, router
  - DHCP hosts: dns, host-albion

- **Updated playbooks** - Added network-netplan role to 7 bare-metal playbooks
  - Positioned after bootstrap-ubuntu-server, before other services
  - Playbooks: belinda, dns, host-albion, host-backups, host-homeassistant, host-storage, router

- **Updated bootstrap role** - Added `netplan.io` package to bootstrap-ubuntu-server for early availability

- **Testing completed successfully**
  - **belinda (static)**: 192.168.1.150/24 - Clean single IP, no DHCP conflicts
  - **dns (DHCP)**: 192.168.1.2/24 - Proper DHCP acquisition, working routing

- **Removed legacy roles**
  - Deleted `network-ip-address-static` (unused)
  - Deleted `network-ip-address-dhcp` (unused)
  - Kept `network-ip-address-forwarding` (active on host-albion for IPv4 routing)

- **Documentation updated** - CLAUDE.md now documents network-netplan role

## Key Decisions

### Mode Auto-Detection Logic

**Decision**: Use `host_ipv4 | default('', true)` for DHCP vs static detection

**Rationale**: YAML empty values (`host_ipv4:`) become `None` in Jinja2, not empty strings. Simple string comparisons like `!= ''` fail. The `default('', true)` filter with truthiness test correctly handles both undefined and empty values.

**Result**: Static mode when `host_ipv4` has a value, DHCP mode otherwise.

### Cloud-Init Handling

**Decision**: Explicitly disable cloud-init network management and remove its netplan config

**Rationale**: Cloud-init's default netplan config enables DHCP. Without disabling it, both configs merge, resulting in interfaces with multiple IPs (both static and DHCP).

**Implementation**:
- Creates `/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg`
- Removes `/etc/netplan/50-cloud-init.yaml`

### Variable Naming

**Decision**: Use `host_primary_interface` instead of reusing `configure_dns_linkdevice_physical`

**Rationale**: Cleaner separation of concerns. Network configuration uses dedicated variables, DNS registration uses its own. Avoids confusion between different purposes.

### Single Unified Role vs Separate Roles

**Decision**: Create one `network-netplan` role with conditional logic instead of separate static/DHCP roles

**Rationale**: Simpler to maintain, matches the pattern used in virtual-hetzner, template logic is straightforward enough not to warrant splitting.

## Files Changed

### New Files
- `ansible/roles/network-netplan/defaults/main.yaml`
- `ansible/roles/network-netplan/tasks/main.yaml`
- `ansible/roles/network-netplan/handlers/main.yaml`
- `ansible/roles/network-netplan/templates/50-primary-interface.yaml.j2`
- `ansible/roles/network-netplan/README.md`

### Modified Files

**Host Variables (8 files)**:
- `ansible/inventory/host_vars/belinda/core.yaml`
- `ansible/inventory/host_vars/dns/core.yaml`
- `ansible/inventory/host_vars/host-albion/core.yaml`
- `ansible/inventory/host_vars/host-backups/core.yaml`
- `ansible/inventory/host_vars/host-homeassistant/core.yaml`
- `ansible/inventory/host_vars/host-storage/core.yaml`
- `ansible/inventory/host_vars/router/core.yaml`

**Playbooks (7 files)**:
- `ansible/playbooks/baremetal/belinda/core.yaml`
- `ansible/playbooks/baremetal/dns/core.yaml`
- `ansible/playbooks/baremetal/host-albion/core.yaml`
- `ansible/playbooks/baremetal/host-backups/core.yaml`
- `ansible/playbooks/baremetal/host-homeassistant/core.yaml`
- `ansible/playbooks/baremetal/host-storage/core.yaml`
- `ansible/playbooks/baremetal/router/core.yaml`

**Roles**:
- `ansible/roles/bootstrap-ubuntu-server/defaults/main.yaml`

**Documentation**:
- `CLAUDE.md`

### Deleted Files
- `ansible/roles/network-ip-address-dhcp/` (entire directory)
- `ansible/roles/network-ip-address-static/` (entire directory)

## Current State

### Deployed & Tested
- ✅ **belinda** - Static IP (192.168.1.150/24) working perfectly
- ✅ **dns** - DHCP (192.168.1.2/24) working perfectly

### Ready for Deployment
- ⏳ **host-storage** - Static (192.168.1.116/24)
- ⏳ **host-homeassistant** - Static (192.168.1.130/24)
- ⏳ **host-backups** - Static (192.168.1.118/24)
- ⏳ **host-albion** - DHCP (UK location, Raspberry Pi)
- ⏳ **router** - Static (192.168.1.221/24, interface may need verification)

### Excluded
- ❌ **pikvm** - Runs Arch Linux (PiKVM OS), not Ubuntu, excluded from migration

### Committed
- Commit `1bb0093` - "feat: migrate network configuration from nmcli to netplan"
- 29 files changed, 137 insertions(+), 65 deletions(-)
- References issue #83

## Next Steps

### Immediate Actions

1. **Deploy to production hosts** - Roll out netplan to remaining 5 hosts
   - Recommended order: host-storage → host-homeassistant → host-backups → host-albion → router
   - Can be done with: `ansible-playbook ansible/playbooks/baremetal/<host>/core.yaml --limit <host>`

2. **Validate router interface** - Verify router host uses eth0 (assumed, not confirmed due to unreachable host)

3. **Monitor for issues** - Watch for networking problems during phased rollout

### Future Considerations

1. **Multi-interface support** - Current role only configures primary interface
   - Virtual-hetzner has floating IP example if needed
   - Would require role enhancement for bonding/VLANs

2. **IPv6 support** - Template currently IPv4-only
   - Can add dhcp6/static IPv6 if needed

3. **Custom DNS servers** - Role supports `network_netplan_nameservers` but not currently used
   - Defaults to systemd-resolved

## Notes & Gotchas

### Bug Found During Testing

**Issue**: Empty `host_ipv4:` values triggered static mode with malformed config (`- /24`)

**Root Cause**: YAML's empty value becomes `None` in Jinja2, not an empty string

**Fix**: Changed mode detection from `host_ipv4 != ''` to `host_ipv4 | default('', true)`

**Location**: `ansible/roles/network-netplan/defaults/main.yaml:20`

### Cloud-Init Conflicts

Raspberry Pi images include cloud-init with DHCP-enabled netplan configs. Without disabling cloud-init's network management, both configurations merge, causing dual IP addresses (static + DHCP).

**Solution**: Role now creates cloud-init override and removes its netplan file.

### Pre-Commit Hook Warnings

PyMarkdown warnings in CLAUDE.md are pre-existing (long lines). My changes follow the existing format. Safe to ignore during commit.

### Router Host Status

Router host (192.168.1.221) was unreachable during implementation. Interface defaulted to "eth0" based on typical naming. Should verify actual interface name before production deployment if possible.

### Network-IP-Address-Forwarding

This role was **intentionally kept** - it's for IPv4 packet forwarding via sysctl (routing/NAT), not interface configuration. Still actively used by host-albion.

## Configuration Examples

### Static IP Host (belinda)
```yaml
# host_vars/belinda/core.yaml
host_primary_interface: "eth0"
host_ipv4: 192.168.1.150
host_ipv4_subnet: 24
```

Generates:
```yaml
# /etc/netplan/50-primary-interface.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      addresses:
        - 192.168.1.150/24
      routes:
        - to: default
          via: 192.168.1.1
```

### DHCP Host (dns)
```yaml
# host_vars/dns/core.yaml
host_primary_interface: "eth0"
host_ipv4:  # Empty = DHCP mode
```

Generates:
```yaml
# /etc/netplan/50-primary-interface.yaml
network:
  version: 2
  renderer: networkd
  ethernets:
    eth0:
      dhcp4: true
```

## Testing Validation

Both hosts validated with:
- ✅ Netplan configuration syntax valid (`netplan get`)
- ✅ Interface configured correctly (`ip addr show`)
- ✅ Routing table correct (`ip route show`)
- ✅ SSH connectivity maintained (`ansible <host> -m ping`)
- ✅ No conflicting DHCP addresses on static hosts
- ✅ Cloud-init netplan file removed

---

## Evening Session - Composition Role Refactoring Planning

### Session Overview

Analyzed GitHub issue #134 and created comprehensive implementation plan for refactoring composition roles from non-standard dynamic inclusion pattern to standard Ansible role dependencies with explicit playbook inclusion.

### What Was Done

#### Issue Analysis (GH #134)

- **Examined current composition architecture** - Documented how the `compositions` role currently works
  - Single role included in playbooks with dynamic `include_role` loop
  - Host vars define `compositions:` list of role names to include
  - Creates network, ZFS datasets, config dirs, starts containers, prunes images

- **Identified problems with current approach**
  - Context switching between playbooks and host vars
  - Cannot use Ansible's native dependency management
  - Non-standard pattern difficult for others to understand

- **Explored codebase structure**
  - Reviewed ~39 `composition-*` roles (gitea, homeassistant, reverseproxy, etc.)
  - Examined common patterns across composition roles
  - Analyzed `composition-reverseproxy` (specifically mentioned in issue as potential concern)

#### Implementation Plan Created

- **Created `plans/2026-01-19-composition-role-refactoring.md`** - Comprehensive 5-phase refactoring plan
  - Phase 1: Create `composition-common` role for shared infrastructure
  - Phase 2: Refactor ~39 composition roles to use dependencies
  - Phase 3: Update playbooks to use direct role inclusion
  - Phase 4: Handle special cases (reverseproxy, image pruning)
  - Phase 5: Deprecate old `compositions` role with migration guide

- **Simplified task ordering approach** - Eliminated complex pre/post task coordination
  - Each composition becomes fully self-contained
  - Dependencies run first (create infrastructure)
  - Composition role templates files and starts its own containers
  - No need for batch processing (artifact of loop-based design)

- **Created GH issue #135** - Systemd-based Docker image pruning automation
  - Proposed new role to handle automated image pruning via systemd timer
  - Decouples maintenance from deployment workflow
  - https://github.com/awfulwoman/infra/issues/135

#### Documentation

- Updated plan multiple times based on architectural insights
- Added variable flow diagrams
- Documented benefits, risks, testing strategy
- Included success criteria checklist

### Key Decisions

#### Composition-Common vs Reusing Compositions Role

**Decision**: Create new `composition-common` role instead of refactoring existing `compositions` role in-place

**Rationale**: Allows old and new systems to coexist during migration, clearer naming (singular vs plural), can keep old role with deprecation warning

**Alternative Considered**: Rename and refactor `compositions` role in-place to reduce duplication

#### Task Ordering Simplification

**Decision**: Each composition role starts its own Docker Compose project at end of tasks (no centralized startup)

**Rationale**: The batch processing pattern (template all → start all) was an artifact of the loop-based design, not a requirement. Self-contained compositions are more atomic and idempotent.

**Original Plan**: Complex pre/post task splitting with multiple options (pre/post roles, include_role with tasks_from, block-based pattern)

**Insight**: Docker network creation is idempotent and safe for multiple parallel runs. Each composition can independently create infrastructure, configure itself, and start containers.

#### Image Pruning Strategy

**Decision**: Remove from automation entirely, create separate systemd-based solution (GH #135)

**Rationale**: Image pruning is maintenance, not deployment. Doesn't need to run on every playbook execution. Systemd timer provides proper scheduling and logging.

**Alternatives Rejected**:
- Per-composition pruning (wasteful, runs multiple times)
- End-of-playbook cleanup role (still couples maintenance to deployment)

### Files Changed

#### New Files
- `plans/2026-01-19-composition-role-refactoring.md` - Implementation plan

#### Commits
- `55297eaa` - "docs: add composition role refactoring plan for GH #134"

### Current State

#### Planning Complete
- ✅ Issue #134 analyzed and understood
- ✅ Current architecture documented
- ✅ Proposed architecture designed
- ✅ 5-phase implementation plan created
- ✅ Variable flow documented
- ✅ Risks and mitigations identified
- ✅ Testing strategy outlined
- ✅ Image pruning separated into GH #135
- ✅ Plan committed to repository

#### Ready for Implementation
- ⏳ Phase 1: Create composition-common role
- ⏳ Phase 2: Refactor ~39 composition roles
- ⏳ Phase 3: Update playbooks
- ⏳ Phase 4: Handle special cases
- ⏳ Phase 5: Deprecate old system

### Next Steps

#### Composition Refactoring (GH #134)

1. **Phase 1: Create composition-common role**
   - Create role structure (tasks, meta, defaults)
   - Move network creation (idempotent)
   - Move single-composition ZFS dataset creation
   - Move config directory creation
   - Set composition_root and composition_config variables
   - Test in isolation

2. **Phase 2: Refactor composition roles** (start with simple ones)
   - Add `meta/main.yaml` with composition-common dependency
   - Add `defaults/main.yaml` with composition_name
   - Add Docker Compose startup task to end of tasks/main.yaml
   - Test 2-3 simple compositions first
   - Then tackle composition-reverseproxy (most complex)

3. **Phase 3: Update playbooks**
   - Convert host_vars compositions lists to direct role inclusions
   - Test each playbook individually
   - Verify no container recreation (no downtime)

4. **Phase 4: Handle special cases**
   - Verify composition-reverseproxy works correctly
   - Remove image pruning from compositions role

5. **Phase 5: Deprecate old system**
   - Add deprecation warning to compositions role
   - Document migration path
   - Remove after 1-2 iterations

#### Image Pruning (GH #135)

1. Create `system-docker-prune` or `maintenance-docker-prune` role
2. Implement systemd service and timer
3. Make schedule configurable (daily/weekly/monthly)
4. Add to appropriate hosts

### Notes & Gotchas

#### Composition-Reverseproxy Analysis

**Concern**: Issue #134 specifically asked if reverseproxy role has issues with non-normal structure

**Finding**: No special dependencies found. Role just has more setup tasks than typical compositions:
- Templates Traefik configuration
- Manages provider configurations
- Creates nginx containers (catch-all, status pages)
- More complex but structurally normal

**Conclusion**: Will work fine with new structure, just needs proper meta/main.yaml like others

#### Batch Processing Not Required

**Key Insight**: Current code templates all compose files first, then starts all containers in a loop. This feels like it should be required, but it's actually just an artifact of the loop-based design.

**Reality**: Each composition can independently:
1. Get infrastructure (via composition-common dependency)
2. Template its docker-compose.yaml
3. Start its containers
4. No coordination needed between compositions

**Benefit**: More atomic, better for idempotency, easier to test individual compositions

#### Variable Scoping

**Important**: `composition_common` must receive `composition_name` from parent role, then calculate and set `composition_root` and `composition_config` for the parent to use.

**Flow**:
```
composition-gitea (defaults: composition_name="gitea")
  → depends on composition-common (receives composition_name)
      → sets composition_root, composition_config
  → uses composition_root, composition_config in tasks
```

#### Docker Network Idempotency

The `community.docker.docker_network` module is idempotent - safe to call multiple times. When multiple compositions run in parallel/sequence, each calling composition-common, the network creation task will succeed for the first and be a no-op for others.

### References

- GitHub Issue #134: https://github.com/awfulwoman/infra/issues/134
- GitHub Issue #135: https://github.com/awfulwoman/infra/issues/135
- Plan: `plans/2026-01-19-composition-role-refactoring.md`
- Current compositions role: `ansible/roles/compositions/tasks/main.yaml`
- Example composition roles: `ansible/roles/composition-{gitea,homeassistant,reverseproxy}/`
