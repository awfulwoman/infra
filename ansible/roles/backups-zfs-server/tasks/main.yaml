# ###################################################################
# Prepare a server to receive ZFS datasets
# ###################################################################

- name: Ensure apt packages are installed
  become: true
  ansible.builtin.apt:
    name:
      - zfsutils-linux
      - acl
      - mosquitto-clients
      - pv  # For bandwidth limiting in zfs-push-backups
      - python3
      - python3-venv
      - python3-pip
    state: present

# TODO: is this still needed?
- name: Publish backup server public key as fact
  ansible.builtin.set_fact:
    public_key: "{{ vault_zfsbackups_public_key }}"

- name: Ensure script working dir exists
  become: true
  ansible.builtin.file:
    path: "/opt/zfsbackup"
    state: directory
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    mode: "0774"

- name: Check if virtual environment exists
  ansible.builtin.stat:
    path: "/opt/zfsbackup/bin/python"
  register: venv_python

- name: Create Python virtual environment for backup scripts
  become: true
  ansible.builtin.command:
    cmd: python3 -m venv /opt/zfsbackup
    creates: /opt/zfsbackup/bin/activate
  when: not venv_python.stat.exists

- name: Ensure virtual environment has correct ownership
  become: true
  ansible.builtin.file:
    path: "/opt/zfsbackup"
    state: directory
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    recurse: true

- name: Ensure backup scripts exist
  become: true
  ansible.builtin.template:
    src: "templates/zfs-{{ item }}-backups.py"
    dest: "{{ backups_zfs_server_script_path }}/zfs-{{ item }}-backups"
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    mode: "0774"
  loop:
    - pull
    - push

# Fix for backup script
# see https://unix.stackexchange.com/questions/374093/why-doesnt-sudo-sh-source-profile-d-scripts
- name: Add script to system-wide $PATH
  become: true
  ansible.builtin.copy:
    dest: /etc/profile.d/custom-path-zfs-backup.sh
    content: 'PATH=$PATH:{{ backups_zfs_server_script_path }}'
    owner: root
    group: root
    mode: "0644"

- name: DEBUG datasets raw
  when: backups_zfs_server_debug
  ansible.builtin.debug:
    msg: >-
      {{ hostvars[item].zfs | zfs_critical_datasets }}
  loop: "{{ groups[backups_zfs_server_pull_group] }}"

# Using namespaces because of Jinja weirdness
# https://stackoverflow.com/a/78339774
- name: Add host info to datasets
  ansible.builtin.set_fact:
    backup_datasets: >-
      {% set data = namespace(test=[]) %}
      {%- for ds in (hostvars[item].zfs | zfs_critical_datasets) -%}
        {% set data.test = data.test + [{'dataset': (item ~ '/' ~ ds.dataset), 'properties': (ds.properties | default({})) }] %}
      {%- endfor -%}
      {{ (backup_datasets | default([])) + data.test }}
  loop: "{{ groups[backups_zfs_server_pull_group] }}"

- name: DEBUG backup_datasets
  when: backups_zfs_server_debug
  ansible.builtin.debug:
    msg: "{{ backup_datasets }}"

- name: Ensure backup parent dataset has canmount=off
  become: true
  community.general.zfs:
    name: "{{ backups_zfs_server_local_dataset }}"
    extra_zfs_properties:
      canmount: off
    state: present

- name: Ensure backup datasets exist
  become: true
  community.general.zfs:
    name: "{{ backups_zfs_server_local_dataset }}/{{ item.dataset }}"
    extra_zfs_properties:
      acltype: posix
      xattr: sa
      canmount: off
    state: present
  loop: "{{ backup_datasets }}"

# TODO: remove this if not needed
- name: "Ensure user can sudo without password"
  become: true
  community.general.sudoers:
    name: allow-zfsbackup
    state: present
    user: "{{ ansible_user }}"
    nopassword: true
    commands:
      - "{{ backups_zfs_server_script_path }}/zfs-backups"

- name: "Ensure normal user has permissions on backup datasets"
  become: true
  community.general.zfs_delegate_admin:
    name: "{{ backups_zfs_server_local_dataset }}"
    users: "{{ ansible_user }}"
    permissions: send,compression,mountpoint,create,mount,receive,rollback,destroy,release,hold,userprop,readonly,canmount,dedup,xattr,acltype
    descendents: true

- name: Ensure .ssh directory exists
  ansible.builtin.file:
    dest: "/home/{{ ansible_user }}/.ssh"
    mode: "0700"
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"
    state: directory

- name: Ensure SSH backup user key exists
  ansible.builtin.copy:
    content: "{{ vault_zfsbackups_privatekey_b64 | b64decode }}"
    dest: "/home/{{ ansible_user }}/.ssh/id_rsa"
    mode: "0600"
    owner: "{{ ansible_user }}"
    group: "{{ ansible_user }}"

- name: Ensure .ssh directory exists for root
  become: true
  ansible.builtin.file:
    dest: "/root/.ssh"
    mode: "0700"
    owner: root
    group: root
    state: directory

- name: Ensure SSH backup user key exists for root
  become: true
  ansible.builtin.copy:
    content: "{{ vault_zfsbackups_privatekey_b64 | b64decode }}"
    dest: "/root/.ssh/id_rsa"
    mode: "0600"
    owner: root
    group: root

- name: Ensure that pull backup cronjobs are managed for each client
  become: true
  vars:
    _datasets: "{{ hostvars[item].zfs | default({}) | zfs_backup_datasets }}"
    _has_datasets: "{{ _datasets | length > 0 }}"
  ansible.builtin.cron:
    name: "zfs-pull-backups {{ item }}"
    hour: "{{ backups_zfs_server_cron_hour }}"
    minute: "{{ backups_zfs_server_cron_minute }}"
    job: >-
      {{ backups_zfs_server_script_path }}/zfs-pull-backups
      --host {{ item }}
      --user {{ vault_zfsbackups_user }}
      --datasets {{ _datasets | map(attribute='dataset') | join(' ') }}
      >/dev/null
    state: "{{ 'present' if _has_datasets else 'absent' }}"
  loop: "{{ groups[backups_zfs_server_pull_group] }}"

# ###################################################################
# Offsite push - replicate critical datasets to offsite hosts
# ###################################################################

- name: Build list of local datasets eligible for offsite replication
  when: backups_zfs_server_offsite_enabled
  ansible.builtin.set_fact:
    offsite_datasets: >-
      {% set data = namespace(datasets=[]) %}
      {%- for client in groups[backups_zfs_server_pull_group] -%}
        {%- for ds in (hostvars[client].zfs | default({}) | zfs_offsite_datasets) -%}
          {% set data.datasets = data.datasets + [backups_zfs_server_local_dataset ~ '/' ~ client ~ '/' ~ ds.dataset] %}
        {%- endfor -%}
      {%- endfor -%}
      {{ data.datasets }}

- name: DEBUG offsite_datasets
  when: backups_zfs_server_offsite_enabled and backups_zfs_server_debug
  ansible.builtin.debug:
    msg: "{{ offsite_datasets }}"

- name: Ensure that offsite push cronjobs are managed for each offsite host
  become: true
  vars:
    _offsite_enabled: "{{ backups_zfs_server_offsite_enabled | default(false) }}"
    _offsite_destination: "{{ hostvars[item].backups_zfs_archive_offsite_dataset | default('fastpool/encryptedbackups') }}"
    _has_datasets: "{{ offsite_datasets | default([]) | length > 0 }}"
    _bwlimit_arg: "{{ ('--bwlimit ' ~ backups_zfs_server_offsite_bwlimit) if backups_zfs_server_offsite_bwlimit else '' }}"
    _should_enable: "{{ _offsite_enabled and _has_datasets }}"
  ansible.builtin.cron:
    name: "zfs-push-backups {{ item }}"
    hour: "{{ backups_zfs_server_offsite_cron_hour }}"
    minute: "{{ backups_zfs_server_offsite_cron_minute }}"
    job: >-
      {{ backups_zfs_server_script_path }}/zfs-push-backups
      --host {{ item }}
      --user {{ vault_zfsbackups_user }}
      --destination {{ _offsite_destination }}
      --datasets {{ offsite_datasets | default([]) | join(' ') }}
      {{ _bwlimit_arg }}
      >/dev/null
    state: "{{ 'present' if _should_enable else 'absent' }}"
  loop: "{{ groups[backups_zfs_server_offsite_group] | default([]) }}"
